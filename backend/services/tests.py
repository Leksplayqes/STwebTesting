"""Service layer encapsulating pytest job orchestration."""
from __future__ import annotations

import os
import re
import sys
import time
from functools import lru_cache
from pathlib import Path
from subprocess import PIPE, STDOUT, Popen
from threading import RLock
from typing import Dict, Iterable, List, Optional

from fastapi import BackgroundTasks, HTTPException

from shared.catalogs import ALARM_TESTS_CATALOG, SYNC_TESTS_CATALOG

from ..config import PROJECT_ROOT, REPORT_DIR, ensure_config
from ..jobs import job_path, load_jobs_on_startup, save_job
from ..models import TestsRunRequest
from ..result_repository import ResultRecord, ResultRepository
from .tunnels import (
    TunnelConfigurationError,
    TunnelManagerError,
    TunnelPortsBusyError,
    TunnelService,
    get_tunnel_service,
)


class TestExecutionService:
    """Coordinates pytest execution jobs and their lifecycle."""

    def __init__(
        self,
        tunnel_service: TunnelService,
        *,
        project_root: Path = PROJECT_ROOT,
        report_dir: Path = REPORT_DIR,
    ) -> None:
        self._tunnel_service = tunnel_service
        self._project_root = project_root
        self._report_dir = report_dir
        self._results = ResultRepository(limit=20)
        self._running_procs: Dict[str, Popen] = {}
        self._lock = RLock()
        load_jobs_on_startup(self._results)

    # ------------------------------------------------------------------
    def list_catalogs(self) -> Dict[str, Dict[str, str]]:
        return {"alarm_tests": ALARM_TESTS_CATALOG, "sync_tests": SYNC_TESTS_CATALOG}

    def list_jobs(self) -> List[Dict[str, object]]:
        return [record.to_dict() for record in self._results.list()]

    def get_job(self, job_id: str) -> ResultRecord:
        record = self._results.get(job_id)
        if not record:
            raise HTTPException(status_code=404, detail="job not found")
        return record

    def job_file(self, job_id: str) -> Path:
        return job_path(job_id)

    # ------------------------------------------------------------------
    def run(self, request: TestsRunRequest, background_tasks: BackgroundTasks) -> Dict[str, object]:
        job_id = _generate_job_id()
        nodeids = [_norm_nodeid(x) for x in (request.selected_tests or []) if x.strip()]
        if not nodeids:
            raise HTTPException(status_code=400, detail="Не выбраны тесты для запуска")

        cfg = ensure_config()
        ip = (cfg.get("CurrentEQ") or {}).get("ipaddr") or ""
        password = (cfg.get("CurrentEQ") or {}).get("pass") or ""
        if not ip:
            raise HTTPException(status_code=400, detail="Не настроен IP оборудования для запуска тестов")

        lease_key = self._lease_key(job_id)
        try:
            lease = self._tunnel_service.reserve(
                lease_key,
                "tests",
                ip=ip,
                username="admin",
                password=password,
                ttl=3600.0,
                track=True,
            )
        except TunnelPortsBusyError as exc:
            raise HTTPException(status_code=503, detail=str(exc)) from exc
        except TunnelConfigurationError as exc:
            raise HTTPException(status_code=409, detail=str(exc)) from exc
        except TunnelManagerError as exc:
            raise HTTPException(status_code=500, detail=f"Ошибка подготовки туннеля: {exc}") from exc

        started = time.time()
        payload: Dict[str, object] = {
            "id": job_id,
            "config": request.model_dump(),
            "started": started,
            "finished": None,
            "summary": {
                "status": "running",
                "total": 0,
                "passed": 0,
                "failed": 0,
                "skipped": 0,
                "duration": 0.0,
            },
            "cases": [],
            "stdout": "",
            "stderr": "",
            "returncode": None,
            "expected_total": None,
            "lease_port": lease.port,
        }
        try:
            record = self._results.create(
                record_id=job_id,
                type="tests",
                status="running",
                payload=payload,
                started_at=started,
            )
            save_job(job_id, self._results)
        except Exception:
            self._tunnel_service.release(lease_key)
            raise

        try:
            background_tasks.add_task(self._execute_tests, job_id, nodeids)
        except Exception:
            self._tunnel_service.release(lease_key)
            raise
        return {"success": True, "job_id": job_id, "record": record.to_dict()}

    def stop(self, job_id: str) -> Dict[str, object]:
        try:
            record = self.get_job(job_id)
        except HTTPException:
            return {"success": False, "error": "job not found"}

        job = record.payload
        proc = self._running_procs.get(job_id)
        if not proc:
            if (job.get("summary") or {}).get("status") == "running":
                job["summary"]["status"] = "stopped"
                job["finished"] = time.time()
                self._results.update(
                    job_id,
                    status="stopped",
                    payload=job,
                    finished_at=job["finished"],
                )
                save_job(job_id, self._results)
            self._tunnel_service.release(self._lease_key(job_id))
            return {"success": True, "message": "job is not running"}

        try:
            proc.terminate()
            try:
                proc.wait(timeout=5)
            except Exception:
                proc.kill()
            code = proc.returncode
        except Exception as exc:
            return {"success": False, "error": f"terminate failed: {exc}"}
        finally:
            with self._lock:
                self._running_procs.pop(job_id, None)

        cases = job.get("cases") or []
        job["returncode"] = code
        job["finished"] = time.time()
        job["summary"] = _recalc_summary(cases, finished=True)
        self._results.update(
            job_id,
            status="stopped",
            payload=job,
            finished_at=job["finished"],
        )
        save_job(job_id, self._results)
        self._tunnel_service.release(self._lease_key(job_id))
        return {"success": True, "message": "job stopped"}

    # Internal helpers -------------------------------------------------
    def _lease_key(self, job_id: str) -> str:
        return f"tests:{job_id}"

    def _execute_tests(self, job_id: str, nodeids: Iterable[str]) -> None:
        record = self._results.get(job_id)
        if not record:
            return

        payload = record.payload
        payload["expected_total"] = None
        report_path = str(self._report_dir / f"{job_id}.xml")
        self._results.update(job_id, payload=payload)
        save_job(job_id, self._results)

        cmd = [
            sys.executable,
            "-m",
            "pytest",
            "-vv",
            "-rA",
            "--tb=short",
            "--color=no",
            f"--junitxml={report_path}",
            *nodeids,
        ]
        proc = Popen(
            cmd,
            cwd=str(self._project_root),
            text=True,
            stdout=PIPE,
            stderr=STDOUT,
            bufsize=1,
            universal_newlines=True,
        )
        with self._lock:
            self._running_procs[job_id] = proc

        collect_re = re.compile(r"collected\s+(\d+)\s+items?")
        cases_map: Dict[str, Dict[str, object]] = {}
        payload.update(
            {
                "stdout": "",
                "stderr": "",
                "cases": [],
                "summary": {
                    "status": "running",
                    "total": 0,
                    "passed": 0,
                    "failed": 0,
                    "skipped": 0,
                    "duration": 0.0,
                },
            }
        )
        self._results.update(job_id, status="running", payload=payload)
        save_job(job_id, self._results)

        try:
            if proc.stdout is not None:
                for line in proc.stdout:
                    mcol = collect_re.search(line)
                    if mcol:
                        try:
                            payload["expected_total"] = int(mcol.group(1))
                        except Exception:
                            payload["expected_total"] = None
                    payload["stdout"] += line
                    match = _VERBOSE_LINE.match(line.strip())
                    if match:
                        nodeid = _norm_nodeid(match.group("nodeid").strip())
                        status = match.group("status")
                        case = cases_map.get(nodeid) or {
                            "name": nodeid.split("::")[-1],
                            "nodeid": nodeid,
                            "status": status,
                            "duration": None,
                            "message": None,
                        }
                        case["status"] = status
                        cases_map[nodeid] = case
                        payload["cases"] = list(cases_map.values())
                        payload["summary"] = _recalc_summary(payload["cases"], finished=False)
                        self._results.update(
                            job_id,
                            status=payload["summary"].get("status", "running"),
                            payload=payload,
                        )
                        save_job(job_id, self._results)
            proc.wait()
            payload["returncode"] = proc.returncode
            payload["finished"] = time.time()
            self._results.update(job_id, payload=payload)
            save_job(job_id, self._results)

            try:
                if os.path.exists(report_path):
                    final_cases, _ = _parse_junit_report(report_path)
                    final_map = {case["nodeid"]: case for case in final_cases}
                    for nodeid, live in list(cases_map.items()):
                        if nodeid in final_map:
                            merged = final_map[nodeid]
                            merged["status"] = live.get("status", merged["status"])
                            merged["duration"] = merged.get("duration") or live.get("duration")
                            merged["message"] = merged.get("message") or live.get("message")
                            final_map[nodeid] = merged
                    payload["cases"] = list(final_map.values())
                    payload["summary"] = _recalc_summary(payload["cases"], finished=True)
                    self._results.update(
                        job_id,
                        status=payload["summary"].get("status", "finished"),
                        payload=payload,
                        finished_at=payload.get("finished"),
                    )
                    save_job(job_id, self._results)
                elif not payload.get("cases"):
                    payload["summary"] = {
                        "status": "error",
                        "total": 0,
                        "passed": 0,
                        "failed": 1,
                        "skipped": 0,
                        "duration": 0.0,
                        "message": "pytest did not produce junit xml; check stdout/stderr",
                    }
                    self._results.update(
                        job_id,
                        status="error",
                        payload=payload,
                        finished_at=payload.get("finished"),
                    )
                    save_job(job_id, self._results)
            except Exception as exc:
                payload["summary"] = {
                    "status": "error",
                    "total": len(payload.get("cases") or []),
                    "passed": 0,
                    "failed": 1,
                    "skipped": 0,
                    "duration": 0.0,
                    "message": f"junit merge failed: {exc}",
                }
                self._results.update(
                    job_id,
                    status="error",
                    payload=payload,
                    finished_at=payload.get("finished"),
                )
                save_job(job_id, self._results)
        finally:
            with self._lock:
                self._running_procs.pop(job_id, None)
            self._tunnel_service.release(self._lease_key(job_id))
            if payload.get("finished") is None:
                payload["finished"] = time.time()
                self._results.update(
                    job_id,
                    payload=payload,
                    finished_at=payload["finished"],
                )
            save_job(job_id, self._results)

    # Public accessors -------------------------------------------------
    @property
    def results(self) -> ResultRepository:
        return self._results


def _generate_job_id() -> str:
    import uuid

    return uuid.uuid4().hex[:12]


def _norm_nodeid(node_id: str) -> str:
    return node_id.replace(" ::", "::").replace(":: ", "::").replace(" / ", "/").strip()


def _recalc_summary(cases: Iterable[Dict[str, object]], finished: bool) -> Dict[str, object]:
    cases_list = list(cases)
    total = len(cases_list)
    passed = sum(1 for case in cases_list if case["status"] == "PASSED")
    failed = sum(1 for case in cases_list if case["status"] in ("FAILED", "ERROR"))
    skipped = sum(1 for case in cases_list if case["status"] == "SKIPPED")
    duration = sum(float(case.get("duration") or 0.0) for case in cases_list)
    status = "running" if not finished else ("passed" if failed == 0 else "failed")
    return {
        "status": status,
        "total": total,
        "passed": passed,
        "failed": failed,
        "skipped": skipped,
        "duration": duration,
    }


def _parse_junit_report(xml_path: str) -> tuple[List[Dict[str, object]], Dict[str, object]]:
    import xml.etree.ElementTree as ET

    cases: List[Dict[str, object]] = []
    passed = failed = skipped = errors = 0
    total_time = 0.0

    root = ET.parse(xml_path).getroot()
    for testsuite in root.findall(".//testsuite"):
        for testcase in testsuite.findall("testcase"):
            name = testcase.get("name") or ""
            classname = testcase.get("classname") or ""
            duration = float(testcase.get("time") or 0.0)
            nodeid = f"{classname}::{name}" if classname else name

            status = "PASSED"
            message = None
            failure = testcase.find("failure")
            error = testcase.find("error")
            skipped_el = testcase.find("skipped")
            if failure is not None:
                status, message, failed = "FAILED", (failure.get("message") or "").strip(), failed + 1
            elif error is not None:
                status, message, errors = "ERROR", (error.get("message") or "").strip(), errors + 1
            elif skipped_el is not None:
                status, message, skipped = "SKIPPED", (skipped_el.get("message") or "").strip(), skipped + 1
            else:
                passed += 1

            total_time += duration
            cases.append(
                {
                    "name": name,
                    "nodeid": nodeid,
                    "status": status,
                    "duration": duration,
                    "message": message,
                }
            )

    summary = {
        "status": ("failed" if (failed or errors) else "passed"),
        "total": len(cases),
        "passed": passed,
        "failed": failed + errors,
        "skipped": skipped,
        "duration": total_time,
    }
    return cases, summary


@lru_cache()
def get_test_service() -> TestExecutionService:
    return TestExecutionService(get_tunnel_service())


_VERBOSE_LINE = re.compile(r"^(?P<nodeid>[^ ]+::[^\s]+?)\s+(?P<status>PASSED|FAILED|ERROR|SKIPPED|XPASS|XFAIL)")

__all__ = [
    "TestExecutionService",
    "get_test_service",
]
